{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdddc3e3",
   "metadata": {},
   "source": [
    "### March 17 Assignment, Feature Engineering-I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eed218",
   "metadata": {},
   "source": [
    "#### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be748fe",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "- Missing values in a dataset refer to the absence of a particular value or information in one or more variables or observations. Missing values can occur due to various reasons, such as data collection errors, incomplete surveys, or technical issues.\n",
    "\n",
    "- It is essential to handle missing values because they can lead to biased or unreliable analysis and modeling results. Ignoring missing values can lead to incorrect conclusions, biased parameter estimates, and reduced statistical power. Missing values can also affect the performance of machine learning algorithms, as many models cannot handle missing data directly.\n",
    "\n",
    "- Some algorithms that are not affected by missing values include decision trees (e.g., Random Forests and Gradient Boosting), K-nearest neighbors (KNN), and algorithms based on probabilistic graphical models (e.g., Naive Bayes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1081ea",
   "metadata": {},
   "source": [
    "#### Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da65eae",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Techniques used to handle missing data include:\n",
    "\n",
    "- Mean/Median/Mode imputation: Replace missing values with the mean, median, or mode of the variable.\n",
    "Forward Fill/Backward Fill: Propagate the last observed value forward or the next observed value backward to fill missing values.\n",
    "Dropping missing values: Remove observations or variables with missing values.\n",
    "Model-based imputation: Use statistical models to estimate missing values based on other variables.\n",
    "Multiple imputation: Generate multiple imputations using statistical models and combine the results.\n",
    "\n",
    "Example using Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78512b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  6.]\n",
      " [ 2.  8.]\n",
      " [ 3.  8.]\n",
      " [ 4.  8.]\n",
      " [ 5. 10.]]\n",
      "     A     B\n",
      "0  1.0   6.0\n",
      "1  2.0   6.0\n",
      "2  2.0   8.0\n",
      "3  4.0   8.0\n",
      "4  5.0  10.0\n",
      "     A     B\n",
      "0  1.0   6.0\n",
      "4  5.0  10.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "data = pd.DataFrame({'A': [1, 2, np.nan, 4, 5],\n",
    "                     'B': [6, np.nan, 8, np.nan, 10]})\n",
    "\n",
    "# Mean imputation\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "data_mean_imputed = mean_imputer.fit_transform(data)\n",
    "print(data_mean_imputed)\n",
    "\n",
    "# Forward fill\n",
    "data_forward_filled = data.ffill()\n",
    "print(data_forward_filled)\n",
    "\n",
    "# Dropping missing values\n",
    "data_dropped = data.dropna()\n",
    "print(data_dropped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb554dd0",
   "metadata": {},
   "source": [
    "##### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f80af26",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "- Imbalanced data refers to a situation where the classes or categories in a dataset are not represented equally. In other words, there is a significant disparity in the number of instances between different classes.\n",
    "\n",
    "- If imbalanced data is not handled, it can lead to biased and unreliable predictions. Machine learning models tend to be biased towards the majority class and may have poor performance on the minority class. The model might learn to favor the majority class, resulting in lower accuracy, precision, recall, or F1-score for the minority class. Imbalanced data can also lead to incorrect assessments of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424aea93",
   "metadata": {},
   "source": [
    "#### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sapling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85af585",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Up-sampling and down-sampling are techniques used to address class imbalance in imbalanced datasets.\n",
    "\n",
    "- Up-sampling involves increasing the number of instances in the minority class to match the number of instances in the majority class. This can be achieved by randomly duplicating existing instances or generating synthetic instances based on existing minority class samples.\n",
    "\n",
    "- Down-sampling involves decreasing the number of instances in the majority class to match the number of instances in the minority class. This can be done by randomly selecting a subset of instances from the majority class.\n",
    "\n",
    "- The choice between up-sampling and down-sampling depends on the specific problem and dataset characteristics. Up-sampling can be useful when the dataset has limited samples of the minority class, while down-sampling can be appropriate when there is a large number of instances in the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67bea05",
   "metadata": {},
   "source": [
    "#### Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0e646",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "- Data augmentation is a technique used to increase the size of a dataset by creating new synthetic samples based on existing samples. It is commonly employed in machine learning tasks, especially when the available dataset is limited.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a specific data augmentation method used to address class imbalance.\n",
    "\n",
    "- It generates synthetic samples for the minority class by interpolating between existing minority class samples. SMOTE identifies the k nearest neighbors for each minority class sample, and synthetic samples are created by combining the features of the minority sample with randomly selected neighbors.\n",
    "\n",
    "- SMOTE helps to balance the class distribution and provides more training samples for the minority class, improving the performance of machine learning models on imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0005d",
   "metadata": {},
   "source": [
    "#### Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a889df",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "- Outliers in a dataset are observations that deviate significantly from the majority of other observations. They can be extreme values or data points that are inconsistent with the rest of the data. Outliers can arise due to measurement errors, data corruption, or genuine anomalies in the data.\n",
    "\n",
    "- Handling outliers is essential because they can distort statistical analyses and modeling results. Outliers can disproportionately influence statistical measures such as the mean and standard deviation, leading to biased estimates. Outliers can also affect the performance of machine learning models by influencing the fitting process and reducing the accuracy of predictions.\n",
    "\n",
    "- It is important to identify and handle outliers appropriately, considering the specific context and characteristics of the data. Outliers can be handled by removing them if they are due to data entry errors or transformed if they follow a specific distribution. Robust statistical techniques that are less sensitive to outliers, such as median-based methods or robust regression models, can also be employed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3882f4",
   "metadata": {},
   "source": [
    "#### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ea1cf",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "When dealing with missing data in customer data analysis, some techniques that can be used include:\n",
    "\n",
    "- Mean/median imputation: Fill missing values with the mean or median of the respective variable.\n",
    "- Mode imputation: Fill missing values with the mode (most frequent value) of the respective variable.\n",
    "- Predictive imputation: Use machine learning models or regression models to predict missing values based on other variables.\n",
    "- Multiple imputation: Generate multiple imputations by modeling the missing values based on other variables and combine the results.\n",
    "- Dropping missing values: Exclude observations with missing values from the analysis if the missingness is random or not substantial.\n",
    "\n",
    "The choice of technique depends on the nature of the data, the amount of missingness, and the specific requirements of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ee30a",
   "metadata": {},
   "source": [
    "#### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869938ab",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Strategies to determine if the missing data is missing at random or exhibits a pattern can include:\n",
    "\n",
    "- Visual analysis: Plotting patterns of missing data using heatmaps or missing data matrices to identify any systematic patterns or relationships.\n",
    "- Statistical tests: Conducting statistical tests to determine if the missingness is associated with other variables in the dataset.\n",
    "- Missing data mechanisms: Analyzing the mechanism of missingness, such as missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR), using statistical techniques or assumptions.\n",
    "\n",
    "By investigating the patterns and mechanisms of missing data, researchers can make informed decisions on how to handle missing data appropriately and minimize potential biases in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f8ba6",
   "metadata": {},
   "source": [
    "#### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9119b",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Strategies to evaluate the performance of machine learning models on an imbalanced dataset with a low percentage of occurrences include:\n",
    "\n",
    "- Precision, recall, and F1-score: These metrics focus on the performance of the minority class and provide insights into the model's ability to correctly identify the occurrences.\n",
    "- Area under the Receiver Operating Characteristic curve (ROC-AUC): This metric assesses the overall performance of the model by considering the trade-off between true positive rate (sensitivity) and false positive rate.\n",
    "- Confusion matrix: Analyzing the confusion matrix can provide detailed information about the model's performance, including true positives, true negatives, false positives, and false negatives.\n",
    "- Resampling techniques: Employing resampling techniques such as cross-validation or stratified sampling to ensure the evaluation is not biased by the class imbalance.\n",
    "\n",
    "By considering these strategies, researchers can obtain a comprehensive understanding of the model's performance and make appropriate adjustments to improve classification accuracy and predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8e447",
   "metadata": {},
   "source": [
    "#### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2280548b",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "To balance a dataset and down-sample the majority class when dealing with an unbalanced dataset, a common method is random undersampling. This involves randomly selecting a subset of instances from the majority class to match the number of instances in the minority class. The goal is to reduce the dominance of the majority class and achieve a more balanced representation of the classes in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cab47",
   "metadata": {},
   "source": [
    "#### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b06f79",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "To balance a dataset and up-sample the minority class when dealing with a low percentage of occurrences, a common method is synthetic oversampling. One popular technique is SMOTE (Synthetic Minority Over-sampling Technique). SMOTE generates synthetic samples by interpolating between existing minority class samples and their nearest neighbors. By creating synthetic instances, SMOTE increases the number of instances in the minority class, thereby improving the representation and addressing the class imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
